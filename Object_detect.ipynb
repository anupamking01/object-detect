{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Object-detect.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "lok_HyIFeA8N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U --pre tensorflow==\"2.*\"\n",
        "!pip install tf_slim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gsif3CyN1m-_",
        "outputId": "124d9105-371d-4b71-a766-355b076ec8ea"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow==2.* in /usr/local/lib/python3.7/dist-packages (2.9.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.*) (57.4.0)\n",
            "Requirement already satisfied: tensorboard<2.10,>=2.9 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.*) (2.9.1)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.*) (0.4.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.*) (1.1.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.*) (1.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.*) (3.3.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.*) (0.26.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.*) (1.15.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.*) (1.47.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.*) (3.17.3)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.*) (14.0.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.*) (21.3)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.*) (1.21.6)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.*) (1.6.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.*) (4.1.1)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.*) (3.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.*) (1.14.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.*) (1.1.2)\n",
            "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.*) (2.9.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.*) (0.2.0)\n",
            "Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.*) (1.12)\n",
            "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.*) (2.9.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow==2.*) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow==2.*) (1.5.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.*) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.*) (3.4.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.*) (2.23.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.*) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.*) (1.8.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.*) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.*) (0.6.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.*) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.*) (4.9)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.*) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow==2.*) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow==2.*) (4.12.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow==2.*) (3.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.*) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow==2.*) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow==2.*) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow==2.*) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow==2.*) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow==2.*) (3.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tensorflow==2.*) (3.0.9)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tf_slim in /usr/local/lib/python3.7/dist-packages (1.1.0)\n",
            "Requirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from tf_slim) (1.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pathlib\n",
        "\n",
        "\n",
        "if \"models\" in pathlib.Path.cwd().parts:\n",
        "  while \"models\" in pathlib.Path.cwd().parts:\n",
        "    os.chdir('..')\n",
        "elif not pathlib.Path('models').exists():\n",
        "  !git clone --depth 1 https://github.com/tensorflow/models"
      ],
      "metadata": {
        "id": "7m4fDMXX1q-k"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "cd models/research/\n",
        "protoc object_detection/protos/*.proto --python_out=."
      ],
      "metadata": {
        "id": "Immjm0nE11Gl"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash \n",
        "cd models/research\n",
        "pip install ."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bSTGoGka2A15",
        "outputId": "756ba1ee-1bc6-4f85-bd6a-7593aeceefc5"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR: Directory '.' is not installable. Neither 'setup.py' nor 'pyproject.toml' found.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import six.moves.urllib as urllib\n",
        "import sys\n",
        "import tarfile\n",
        "import tensorflow as tf\n",
        "import zipfile\n",
        "\n",
        "from collections import defaultdict\n",
        "from io import StringIO\n",
        "from matplotlib import pyplot as plt\n",
        "from PIL import Image\n",
        "from IPython.display import display"
      ],
      "metadata": {
        "id": "wVcnA7By2EL5"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install object_detection"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tD9bFrN62noE",
        "outputId": "6ca17b5c-0b69-4f23-80e7-4f95d11367c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement object_detection (from versions: none)\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for object_detection\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "\n",
        "sys.path.insert(0, '/content/models/research/')"
      ],
      "metadata": {
        "id": "9ZEU4m8f22Yo"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from object_detection.utils import ops as utils_ops\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import visualization_utils as vis_util"
      ],
      "metadata": {
        "id": "lW9cd5Nv2FLo"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# patch tf1 into `utils.ops`\n",
        "utils_ops.tf = tf.compat.v1\n",
        "\n",
        "# Patch the location of gfile\n",
        "tf.gfile = tf.io.gfile"
      ],
      "metadata": {
        "id": "GPb1RYn2204v"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_model(model_name):\n",
        "  base_url = 'http://download.tensorflow.org/models/object_detection/'\n",
        "  model_file = model_name + '.tar.gz'\n",
        "  model_dir = tf.keras.utils.get_file(\n",
        "    fname=model_name, \n",
        "    origin=base_url + model_file,\n",
        "    untar=True)\n",
        "\n",
        "  print(model_dir)\n",
        "  model_dir = pathlib.Path(model_dir)/\"saved_model\"\n",
        "  (model_dir)\n",
        "  print(model_dir)\n",
        "  model = tf.saved_model.load(str(model_dir))\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "Xe0KZJpo4CFZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List of the strings that is used to add correct label for each box.\n",
        "PATH_TO_LABELS = 'models/research/object_detection/data/mscoco_label_map.pbtxt'\n",
        "category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS, use_display_name=True)"
      ],
      "metadata": {
        "id": "AyPQ3Owj4GSF"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = 'ssd_mobilenet_v1_coco_2017_11_17'\n",
        "detection_model = load_model(model_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1MIY7emG4RV8",
        "outputId": "3626f98e-6c35-44fb-dc69-d5b38ce18da3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/root/.keras/datasets/ssd_mobilenet_v1_coco_2017_11_17\n",
            "/root/.keras/datasets/ssd_mobilenet_v1_coco_2017_11_17/saved_model\n",
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = 'faster_rcnn_resnet50_coco_2018_01_28'\n",
        "detection_model = load_model(model_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49F479TM6Y3U",
        "outputId": "f7c99b60-39fe-40d4-e39a-d247666c7b83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/root/.keras/datasets/faster_rcnn_resnet50_coco_2018_01_28\n",
            "/root/.keras/datasets/faster_rcnn_resnet50_coco_2018_01_28/saved_model\n",
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pZ6AGQyI44HL",
        "outputId": "6a64e333-5a47-4f3b-fd86-3b227f47420d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensorflow.python.training.tracking.autotrackable.AutoTrackable"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://download.tensorflow.org/models/object_detection/faster_rcnn_resnet50_coco_2018_01_28.tar.gz\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K4x18v4J7Hf6",
        "outputId": "f42a648c-786d-4609-b136-9b0ed9a3be77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-08-02 19:18:13--  http://download.tensorflow.org/models/object_detection/faster_rcnn_resnet50_coco_2018_01_28.tar.gz\n",
            "Resolving download.tensorflow.org (download.tensorflow.org)... 74.125.199.128, 2607:f8b0:400e:c02::80\n",
            "Connecting to download.tensorflow.org (download.tensorflow.org)|74.125.199.128|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 381355771 (364M) [application/x-tar]\n",
            "Saving to: ‘faster_rcnn_resnet50_coco_2018_01_28.tar.gz’\n",
            "\n",
            "faster_rcnn_resnet5 100%[===================>] 363.69M   329MB/s    in 1.1s    \n",
            "\n",
            "2022-08-02 19:18:14 (329 MB/s) - ‘faster_rcnn_resnet50_coco_2018_01_28.tar.gz’ saved [381355771/381355771]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip '/content/faster_rcnn_resnet50_coco_2018_01_28.tar.gz'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aUEhzb7g_IRJ",
        "outputId": "9ccb9cf8-95f0-431c-bd69-caf6cfb4fc51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/faster_rcnn_resnet50_coco_2018_01_28.tar.gz\n",
            "  End-of-central-directory signature not found.  Either this file is not\n",
            "  a zipfile, or it constitutes one disk of a multi-part archive.  In the\n",
            "  latter case the central directory and zipfile comment will be found on\n",
            "  the last disk(s) of this archive.\n",
            "unzip:  cannot find zipfile directory in one of /content/faster_rcnn_resnet50_coco_2018_01_28.tar.gz or\n",
            "        /content/faster_rcnn_resnet50_coco_2018_01_28.tar.gz.zip, and cannot find /content/faster_rcnn_resnet50_coco_2018_01_28.tar.gz.ZIP, period.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tarfile\n",
        "  \n",
        "\n",
        "# open file\n",
        "file = tarfile.open('/content/faster_rcnn_resnet50_coco_2018_01_28.tar.gz')\n",
        "  \n",
        "# extracting file\n",
        "file.extractall('/content/')\n",
        "  \n",
        "file.close()\n",
        "  \n"
      ],
      "metadata": {
        "id": "vJnRJoJA_ttc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v1_coco_2017_11_17.tar.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jM9y4EgfAiyc",
        "outputId": "a82254f8-29f8-431b-ba4a-39635c57809e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-08-02 19:22:56--  http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v1_coco_2017_11_17.tar.gz\n",
            "Resolving download.tensorflow.org (download.tensorflow.org)... 74.125.199.128, 2607:f8b0:400e:c02::80\n",
            "Connecting to download.tensorflow.org (download.tensorflow.org)|74.125.199.128|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 76534733 (73M) [application/x-tar]\n",
            "Saving to: ‘ssd_mobilenet_v1_coco_2017_11_17.tar.gz’\n",
            "\n",
            "ssd_mobilenet_v1_co 100%[===================>]  72.99M   117MB/s    in 0.6s    \n",
            "\n",
            "2022-08-02 19:22:57 (117 MB/s) - ‘ssd_mobilenet_v1_coco_2017_11_17.tar.gz’ saved [76534733/76534733]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tarfile\n",
        "  \n",
        "\n",
        "# open file\n",
        "file = tarfile.open('/content/ssd_mobilenet_v1_coco_2017_11_17.tar.gz')\n",
        "  \n",
        "# extracting file\n",
        "file.extractall('/content/')\n",
        "  \n",
        "file.close()"
      ],
      "metadata": {
        "id": "fDMnasYsAvf1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dependencies\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# load graphs using pb file path\n",
        "def load_graph(pb_file):\n",
        "    graph = tf.Graph()\n",
        "    with graph.as_default():\n",
        "        od_graph_def = tf.GraphDef()\n",
        "        with tf.gfile.GFile(pb_file, 'rb') as fid:\n",
        "            serialized_graph = fid.read()\n",
        "            od_graph_def.ParseFromString(serialized_graph)\n",
        "            tf.import_graph_def(od_graph_def, name='') \n",
        "    return graph\n",
        "\n",
        "\n",
        "# returns tensor dictionaries from graph\n",
        "def get_inference(graph, count=0):\n",
        "    with graph.as_default():\n",
        "        ops = tf.get_default_graph().get_operations()\n",
        "        all_tensor_names = {output.name for op in ops for output in op.outputs}\n",
        "        tensor_dict = {}\n",
        "        for key in ['num_detections', 'detection_boxes', 'detection_scores',\n",
        "                    'detection_classes', 'detection_masks', 'image_tensor']:\n",
        "            tensor_name = key + ':0' if count == 0 else '_{}:0'.format(count)\n",
        "            if tensor_name in all_tensor_names:\n",
        "                tensor_dict[key] = tf.get_default_graph().get_tensor_by_name(tensor_name)\n",
        "                                        \n",
        "        return tensor_dict\n",
        "\n",
        "\n",
        "# renames while_context because there is one while function for every graph\n",
        "def rename_frame_name(graphdef, suffix):\n",
        "    for n in graphdef.node:\n",
        "        if \"while\" in n.name:\n",
        "            if \"frame_name\" in n.attr:\n",
        "                n.attr[\"frame_name\"].s = str(n.attr[\"frame_name\"]).replace(\"while_context\",\n",
        "                                                                           \"while_context\" + suffix).encode('utf-8')\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\n",
        "    # your pb file paths\n",
        "    frozenGraphPath2 = '/content/faster_rcnn_resnet50_coco_2018_01_28/frozen_inference_graph.pb'\n",
        "    frozenGraphPath1 = '/content/ssd_mobilenet_v1_coco_2017_11_17/frozen_inference_graph.pb'\n",
        "\n",
        "    # new file name to save combined model\n",
        "    combinedFrozenGraph = 'combined_frozen_inference_graph.pb'\n",
        "\n",
        "    # loads both graphs\n",
        "    graph1 = load_graph(frozenGraphPath1)\n",
        "    graph2 = load_graph(frozenGraphPath2)\n",
        "\n",
        "    # get tensor names from first graph\n",
        "\n",
        "    tensor_dict1 = get_inference(graph1)\n",
        "    with graph1.as_default():\n",
        "\n",
        "        # getting tensors to add crop and resize step\n",
        "        image_tensor = tensor_dict1['image_tensor']\n",
        "        scores = tensor_dict1['detection_scores'][0]\n",
        "        num_detections = tf.cast(tensor_dict1['num_detections'][0], tf.int32)\n",
        "        detection_boxes = tensor_dict1['detection_boxes'][0]\n",
        "\n",
        "        # I had to add NMS becuase my ssd model outputs 100 detections and hence it runs out of memory becuase of huge tensor shape\n",
        "        selected_indices = tf.image.non_max_suppression(detection_boxes, scores, 5, iou_threshold=0.5)\n",
        "        selected_boxes = tf.gather(detection_boxes, selected_indices)\n",
        "\n",
        "        # intermediate crop and resize step, which will be input for second model(FRCNN)\n",
        "        cropped_img = tf.image.crop_and_resize(image_tensor,\n",
        "                                               selected_boxes,\n",
        "                                               tf.zeros(tf.shape(selected_indices), dtype=tf.int32),\n",
        "                                               [300, 60] # resize to 300 X 60\n",
        "                                               )\n",
        "        cropped_img = tf.cast(cropped_img, tf.uint8, name='cropped_img') \n",
        "    gdef1 = graph1.as_graph_def()\n",
        "    gdef2 = graph2.as_graph_def()\n",
        "\n",
        "    g1name = \"graph1\"\n",
        "    g2name = \"graph2\"\n",
        "\n",
        "    # renaming while_context in both graphs\n",
        "    rename_frame_name(gdef1, g1name)\n",
        "    rename_frame_name(gdef2, g2name)\n",
        "\n",
        "    # This combines both models and save it as one\n",
        "    \n",
        "    with tf.Graph().as_default() as g_combined:\n",
        "\n",
        "        x, y = tf.import_graph_def(gdef1, return_elements=['image_tensor:0', 'cropped_img:0'])\n",
        "\n",
        "        z, = tf.import_graph_def(gdef2, input_map={\"image_tensor:0\": y}, return_elements=['detection_boxes:0'])\n",
        "\n",
        "        tf.train.write_graph(g_combined, \"./\", combinedFrozenGraph, as_text=False)\n",
        "\n",
        "    \n",
        " \n",
        "\n"
      ],
      "metadata": {
        "id": "jU3ftpMuA7eJ"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# If you want to test the code with your images, just add path to the images to the TEST_IMAGE_PATHS.\n",
        "PATH_TO_TEST_IMAGES_DIR = pathlib.Path('models/research/object_detection/test_images')\n",
        "TEST_IMAGE_PATHS = sorted(list(PATH_TO_TEST_IMAGES_DIR.glob(\"*.jpg\")))\n",
        "TEST_IMAGE_PATHS"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p4RAJFMGBhVo",
        "outputId": "d5398de7-b738-4c03-dd78-699a685464ce"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PosixPath('models/research/object_detection/test_images/image1.jpg'),\n",
              " PosixPath('models/research/object_detection/test_images/image2.jpg'),\n",
              " PosixPath('models/research/object_detection/test_images/image3.jpg')]"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dependencies\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "import numpy as np\n",
        "\n",
        "IMAGE_SIZE = (12, 8)\n",
        "\n",
        "\n",
        "def get_inference(graph, count=0):\n",
        "    with graph.as_default():\n",
        "        ops = tf.get_default_graph().get_operations()\n",
        "        all_tensor_names = {output.name for op in ops for output in op.outputs}\n",
        "        tensor_dict = {}\n",
        "        for key in ['num_detections', 'detection_boxes', 'detection_scores',\n",
        "                    'detection_classes', 'detection_masks', 'image_tensor']:\n",
        "            tensor_name = key + ':0' if count == 0 else '_{}:0'.format(count)\n",
        "            if tensor_name in all_tensor_names:\n",
        "                tensor_dict[key] = tf.get_default_graph().get_tensor_by_name(tensor_name)\n",
        "                                        \n",
        "        return tensor_dict\n",
        "\n",
        "\n",
        "def load_image_into_numpy_array(image):\n",
        "  (im_width, im_height) = image.size\n",
        "  return np.array(image.getdata()).reshape(\n",
        "      (im_height, im_width, 3)).astype(np.uint8)\n",
        "\n",
        "# load graphs using pb file path\n",
        "def load_graph(pb_file):\n",
        "    graph = tf.Graph()\n",
        "    with graph.as_default():\n",
        "        od_graph_def = tf.GraphDef()\n",
        "        with tf.gfile.GFile(pb_file, 'rb') as fid:\n",
        "            serialized_graph = fid.read()\n",
        "            od_graph_def.ParseFromString(serialized_graph)\n",
        "            tf.import_graph_def(od_graph_def, name='') \n",
        "    return graph\n",
        "\n",
        "combinedFrozenGraph = '/content/combined_frozen_inference_graph.pb'\n",
        "\n",
        "# loads both graphs\n",
        "detection_graph = load_graph(combinedFrozenGraph)\n",
        "tensor_dict1 = get_inference(detection_graph)\n",
        "\n",
        "print(tensor_dict1)\n",
        "with detection_graph.as_default():\n",
        "  with tf.Session(graph=detection_graph) as sess:\n",
        "    for image_path in TEST_IMAGE_PATHS:\n",
        "      image = Image.open(image_path)\n",
        "      # the array based representation of the image will be used later in order to prepare the\n",
        "      # result image with boxes and labels on it.\n",
        "      image_np = load_image_into_numpy_array(image)\n",
        "      # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
        "      image_np_expanded = np.expand_dims(image_np, axis=0)\n",
        "      image_tensor = tensor_dict1['image_tensor']\n",
        "      # Each box represents a part of the image where a particular object was detected.\n",
        "      scores = tensor_dict1['detection_scores'][0]\n",
        "\n",
        "      num_detections = tf.cast(tensor_dict1['num_detections'][0], tf.int32)\n",
        "\n",
        "      detection_boxes = tensor_dict1['detection_boxes'][0]\n",
        "\n",
        "      # Actual detection.\n",
        "      (boxes, scores, classes, num_detections) = sess.run(\n",
        "          [boxes, scores, classes, num_detections],\n",
        "          feed_dict={image_tensor: image_np_expanded})\n",
        "      # Visualization of the results of a detection.\n",
        "      vis_util.visualize_boxes_and_labels_on_image_array(\n",
        "          image_np,\n",
        "          np.squeeze(boxes),\n",
        "          np.squeeze(classes).astype(np.int32),\n",
        "          np.squeeze(scores),\n",
        "          category_index,\n",
        "          use_normalized_coordinates=True,\n",
        "          line_thickness=8)\n",
        "      plt.figure(figsize=IMAGE_SIZE)\n",
        "      plt.imshow(image_np)"
      ],
      "metadata": {
        "id": "IQ0J2UnUJeJS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def nms(dets, thresh):\n",
        "    x1 = dets[:, 0]\n",
        "    y1 = dets[:, 1]\n",
        "    x2 = dets[:, 2]\n",
        "    y2 = dets[:, 3]\n",
        "    scores = dets[:, 4]\n",
        "\n",
        "    areas = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
        "    order = scores.argsort()[::-1]\n",
        "\n",
        "    keep = []\n",
        "    while order.size > 0:\n",
        "        i = order[0]\n",
        "        keep.append(i)\n",
        "        xx1 = np.maximum(x1[i], x1[order[1:]])\n",
        "        yy1 = np.maximum(y1[i], y1[order[1:]])\n",
        "        xx2 = np.minimum(x2[i], x2[order[1:]])\n",
        "        yy2 = np.minimum(y2[i], y2[order[1:]])\n",
        "\n",
        "        w = np.maximum(0.0, xx2 - xx1 + 1)\n",
        "        h = np.maximum(0.0, yy2 - yy1 + 1)\n",
        "        inter = w * h\n",
        "        ovr = inter / (areas[i] + areas[order[1:]] - inter)\n",
        "\n",
        "        inds = np.where(ovr <= thresh)[0]\n",
        "        order = order[inds + 1]\n",
        "\n",
        "    return keep"
      ],
      "metadata": {
        "id": "V5OSHKbGw1XH"
      },
      "execution_count": 111,
      "outputs": []
    }
  ]
}